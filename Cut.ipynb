{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yolo_annotation(annotation_file, image_path):\n",
    "    annotations = []\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split()\n",
    "            class_id = {0:'neuron'}\n",
    "            image = cv2.imread(image_path)\n",
    "            image_height, image_width, _ = image.shape\n",
    "            x_center, y_center, width, height =map(float, data[1:])\n",
    "            # Перевод относительных координат в абсолютные пиксельные координаты\n",
    "            x_center_px = int(x_center * image_width)\n",
    "            y_center_px = int(y_center * image_height)\n",
    "            width_px = int(width * image_width)\n",
    "            height_px = int(height * image_height)\n",
    "    \n",
    "    # Вычисление координат bbox\n",
    "            x1 = int(x_center_px - width_px / 2)\n",
    "            y1 = int(y_center_px - height_px / 2)\n",
    "            x2 = int(x_center_px + width_px / 2)\n",
    "            y2 = int(y_center_px + height_px / 2)\n",
    "            annotations.append((x1, y1, x2, y2))\n",
    "            \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_annotated_regions(image_path, annotation_file, output_folder):\n",
    "\n",
    "    annotations = parse_yolo_annotation(annotation_file, image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    filename = os.path.basename(image_path)[:-4] # Убрал тип jpg\n",
    "\n",
    "    x1_first, y1_first, x2_first, y2_first = annotations[0]\n",
    "    x1_last, y1_last, x2_last, y2_last = annotations[-1]\n",
    "\n",
    "     # Определение координат промежутка между первой и последней аннотациями\n",
    "    x1_interval = max(x1_first, x1_last)\n",
    "    y1_interval = max(y1_first, y1_last)\n",
    "    x2_interval = min(x2_first, x2_last)\n",
    "    y2_interval = min(y2_first, y2_last)\n",
    "\n",
    "    cropped_interval = image[y1_interval:y2_interval, x1_interval:x2_interval]\n",
    "    output_filename = os.path.join(output_folder, f\"cropped_{filename}.jpg\")\n",
    "\n",
    "    cv2.imwrite(output_filename, cropped_interval)\n",
    "    \n",
    "    print(f\"Сохранено обрезанное изображение: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:786: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m annotation_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mminik\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNeuron.v4i.yolov8_640_Ruslan\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSnap-11082_jpg.rf.d5d93d0ef16da65767aefeaa288e4fc7.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mminik\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNeuron.v4i.yolov8_640_Ruslan\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcut_images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcrop_annotated_regions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mcrop_annotated_regions\u001b[1;34m(image_path, annotation_file, output_folder)\u001b[0m\n\u001b[0;32m     17\u001b[0m cropped_interval \u001b[38;5;241m=\u001b[39m image[y1_interval:y2_interval, x1_interval:x2_interval]\n\u001b[0;32m     18\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcropped_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mСохранено обрезанное изображение: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:786: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Пример использования прямая линия\n",
    "image_path = \"C:\\\\Users\\\\minik\\\\Downloads\\\\Neuron.v4i.yolov8_640_Ruslan\\\\train\\images\\\\snaps-52-_jpg.rf.8167b8d8003962ea80f964d3adad4f91.jpg\"\n",
    "annotation_file = 'C:\\\\Users\\\\minik\\\\Downloads\\\\Neuron.v4i.yolov8_640_Ruslan\\\\train\\\\labels\\\\Snap-11082_jpg.rf.d5d93d0ef16da65767aefeaa288e4fc7.txt'\n",
    "output_folder = 'C:\\\\Users\\\\minik\\\\Downloads\\\\Neuron.v4i.yolov8_640_Ruslan\\\\cut_images'\n",
    "crop_annotated_regions(image_path, annotation_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:786: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m annotation_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mminik\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNeuron.v4i.yolov8_640_Ruslan\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msnaps-52-_jpg.rf.8167b8d8003962ea80f964d3adad4f91.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mminik\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNeuron.v4i.yolov8_640_Ruslan\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcut_images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcrop_annotated_regions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mcrop_annotated_regions\u001b[1;34m(image_path, annotation_file, output_folder)\u001b[0m\n\u001b[0;32m     17\u001b[0m cropped_interval \u001b[38;5;241m=\u001b[39m image[y1_interval:y2_interval, x1_interval:x2_interval]\n\u001b[0;32m     18\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcropped_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mСохранено обрезанное изображение: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:786: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Пример использования косая линия\n",
    "image_path = 'C:\\\\Users\\\\minik\\\\Downloads\\\\Neuron.v4i.yolov8_640_Ruslan\\\\train\\\\images\\\\snaps-52-_jpg.rf.8167b8d8003962ea80f964d3adad4f91.jpg'\n",
    "annotation_file = 'C:\\\\Users\\\\minik\\\\Downloads\\\\Neuron.v4i.yolov8_640_Ruslan\\\\train\\\\labels\\\\snaps-52-_jpg.rf.8167b8d8003962ea80f964d3adad4f91.txt'\n",
    "output_folder = 'C:\\\\Users\\\\minik\\\\Downloads\\\\Neuron.v4i.yolov8_640_Ruslan\\\\cut_images'\n",
    "crop_annotated_regions(image_path, annotation_file, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем с маской"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yolo_annotation(annotation_file, image_path):\n",
    "    annotations = []\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split()\n",
    "            class_id = {0:'neuron'}\n",
    "            image = cv2.imread(image_path)\n",
    "            image_height, image_width, _ = image.shape\n",
    "            x_center, y_center, width, height =map(float, data[1:])\n",
    "            # Перевод относительных координат в абсолютные пиксельные координаты\n",
    "            x_center_px = int(x_center * image_width)\n",
    "            y_center_px = int(y_center * image_height)\n",
    "            width_px = int(width * image_width)\n",
    "            height_px = int(height * image_height)\n",
    "    \n",
    "    # Вычисление координат bbox\n",
    "            x1 = int(x_center_px - width_px / 2)\n",
    "            y1 = int(y_center_px - height_px / 2)\n",
    "            x2 = int(x_center_px + width_px / 2)\n",
    "            y2 = int(y_center_px + height_px / 2)\n",
    "            annotations.append((x1, y1, x2, y2))\n",
    "    return annotations\n",
    "\n",
    "annotations = parse_yolo_annotation(annotation_file, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3883951266.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print (an[])\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "for an in annotations:\n",
    "    print (an[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m y_trend \u001b[38;5;241m=\u001b[39m slope \u001b[38;5;241m*\u001b[39m x_trend \u001b[38;5;241m+\u001b[39m intercept\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Построение графика\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow((\u001b[43mimage\u001b[49m))\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_values, y_values, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mПрямоугольники\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# Извлечение координат центров прямоугольников\n",
    "x_values = [(rect[0] + rect[2])  for rect in annotations]\n",
    "y_values = [(rect[1] + rect[3])  for rect in annotations]\n",
    "\n",
    "# Выполнение линейной регрессии\n",
    "slope, intercept = np.polyfit(x_values, y_values, 1)\n",
    "\n",
    "# Построение линии тренда\n",
    "x_trend = np.linspace(min(x_values), min(x_values), 100)\n",
    "y_trend = slope * x_trend + intercept\n",
    "\n",
    "# Построение графика\n",
    "plt.imshow((image))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_values, y_values, label='Прямоугольники')\n",
    "plt.plot(x_trend, y_trend, color='red', linestyle='--', label='Линия тренда')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Линия тренда из прямоугольников')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_point(point1, point2, t):\n",
    "    x = int(point1[0] * (1 - t) + point2[0] * t)\n",
    "    y = int(point1[1] * (1 - t) + point2[1] * t)\n",
    "    return x, y\n",
    "\n",
    "def create_line_coordinates(image_shape, annotations, step=10):\n",
    "    line_coordinates = []\n",
    "\n",
    "    # Определяем точки, через которые проходит линия\n",
    "    points = []\n",
    "    for annotation in annotations:\n",
    "        x1, y1, x2, y2 = annotation\n",
    "        points.append(((x1 + x2) // 2, (y1 + y2) // 2))\n",
    "\n",
    "    # Находим координаты точек на линии с заданным шагом\n",
    "    for i in range(len(points) - 1):\n",
    "        point1 = points[i]\n",
    "        point2 = points[i + 1]\n",
    "        length = np.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "        num_steps = int(length / step)\n",
    "        for j in range(num_steps):\n",
    "            t = j / num_steps\n",
    "            interpolated_point = interpolate_point(point1, point2, t)\n",
    "            line_coordinates.append(interpolated_point)\n",
    "        line_coordinates.append(point2)\n",
    "\n",
    "    return line_coordinates\n",
    "\n",
    "def crop_image_along_line(image_path, annotations, step=10):\n",
    "    # Загрузка изображения\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Создаем координаты линии\n",
    "    line_coordinates = create_line_coordinates(image.shape, annotations, step)\n",
    "\n",
    "    # Находим минимальные и максимальные координаты для обрезки изображения\n",
    "    min_x = min(coord[0] for coord in line_coordinates)\n",
    "    max_x = max(coord[0] for coord in line_coordinates)\n",
    "    min_y = min(coord[1] for coord in line_coordinates)\n",
    "    max_y = max(coord[1] for coord in line_coordinates)\n",
    "\n",
    "    # Обрезаем изображение\n",
    "    cropped_image = image[min_y:max_y, min_x:max_x]\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обрезка изображения вдоль линии с шагом в 300 пикселей, проходящей через все аннотации\n",
    "cropped_image = crop_image_along_line(image_path, annotations, step=10)\n",
    "\n",
    "# Сохранение обрезанного изображения\n",
    "cv2.imwrite('cropped_image_along_line_with_step.jpg', cropped_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
